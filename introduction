--> kubernatis is a container archistration tool. Kubernatis will not know about containers,it will know or it will deals with only pods, 
    and pods is group of containers. 

ARCHITECTURE OF K8S:
C --> clustor (master and worknode)
N --> node
p --> pod
C --> container
A --> application

MASTER NODE COMPONANTS:                                                                          
             1. API server ( API server will take commands from user and exicute and give o/p to user, 
                             and it used to communicate in cluster)     
             2. etcd (it is like a data base to k8s)                                                                                           
             3. controll manager
                         1. cloud controll manager (if we are implementing k8s on could than its called as cc manager)
                         2. kube controll manager ( if we are implementing on non cloud)
             4. scheduler ( it schedules work for worker node/pod based on hardware properties of server)
WORKER NODE COMPONANTS:
             1. kubelete (  it going to be as agent it will inform to master, it is used to monitor to pods(stopped, deleted, or stopped))
             2. kube proxy ( its like a network)
             3. pods( group of containers)
             4. container ( it is vm not having os in it)
             
 we cant setup k8s in many ways:
             self managed kubernatis clusters are,                                        cloud managed kubernatis cluster are
             1.minikube --> single node cluster ( it used to in only dev and test envir)      1. aws kubernatis clusters
             2.kubeadm --> multi node cluster (manual way of creating cluster)                2. azure kubernatis cluster
             3. kap --> multi node cluster (automation way of creating cluster)               3. google cloud cluster
             
  NOTE: In real time we dont use minikube in realtime i.e, production environment.
  
 To setup minikube:
      1. 2cpus
      2. 2gb of ram
      3. 20 gb of ebs volume.
      4. internet connection
      5. one docker install
NOTE: kubectl is command line tool for kubernatis and which is used to exicutes commands on kubernatis cluster.


POD: pod is a group of containers, it is a smallest unit of k8s which can deployable. inside we have containers, inside we have application.
the prod can be created on two ways:
1.Imperative     --> we create pods in this method by using commands 
2. Declarative   --> we create pods in this by using MANIFEST file, and the manifest file is in form of YAML file.
NOTE: It is always best to prefer DECLARATIVE method bcz in imparative it is not possible to define all the info and specifications of a pod

here now installing kubernatis by using script file , here we taking ubutu vm and it has many default directories we get while installing, so its
better to create a new directory and install all the set up for k8s in that directory.

mkdir project, in this we work with k8s now.
vim minikube.sh
          sudo apt update -y
          sudo apt upgrade -y
          sudo apt install curl wget apt-transport-https -y
          sudo curl -fsSL https://get.docker.com -o get-docker.sh
          sudo sh get-docker.sh
          sudo curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
          sudo mv minikube-linux-amd64 /usr/local/bin/minikube
          sudo chmod +x /usr/local/bin/minikube
          sudo minikube version
          sudo curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          sudo curl -LO "https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"
          sudo echo "$(cat kubectl.sha256) kubectl" | sha256sum --check
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
          sudo minikube start --driver=docker --force
now run thsi script as follows
         --> sh minikube.sh 
         ..............................................................................................
now the kubernatis has been installed now we can create pods bu using imparative or declarative method,
IMPERATIVE: creating pods by command line 

        --> kubectl run pod1 --image=sairamana07/movies:latest
        --> kubectl get pods --> to get list of pods 
        --> kubectl get pod -o wide --> it will give additional information  of pods
        --> kubectl describe pod pod1 --> it will give end to end info of pod.
        --> kubectl delete pod pod1 --> to delete pod.
        --> kubectl api-resources --> will give kubernatis information and help about commands.
        
DECLARATIVE: in this we create pod by manifest file, and this manifest file is in yaml format.        
                
        --> vim pod1.yml
                    apiVersion: V1
                    kind: pod
                    metadata:
                      name: pod1
                    spec:
                      containers:
                      - name: cont1
                      image: nginx
         NOT YET TO  BE COMPLETED
********************************************************************************************************************************************
DAY02,09-06-23.
 in generally when we got deleted the pod than the use not cannot able access the application like before, because in normal methods of pod 
 creation we have not to creat a replications of a pod so to over come this we have REPLICA SETS pod creation method.

REPLICA SETS: 
            -> it will creates multiple copys or replicas of a pod, if we delete one pod than the replica set create another pod.
            
            --> vim abcd.yml
                        apiVersion: apps/v1      --> here we are using apps/v1 is version for replicaset
                        kind: ReplicaSet         --> the kind of object is ReplicaSet and here R&S must be capital
                        metadata:
                          labels:                 --> label is a uniq tag used to identify the pod(if we have multiple pods than we want to 
                                                      replicate perticualar group of pods than the label will identify that group of pods by
                                                      the uniq name ex, 5 pods--> swiggy, 5pods--> zomato than if we want to replicate than 
                                                      directly we pickup swiggy pods by allocating the uniq name as label)
                                                      the main purpose assinging label to a pod is to manage multiple pods at a single time
                                                      with same labels.
                            app: swiggy      --> creating pod name
                            name: swiggy-rs   --> we can use rs or replicaset and rs is a shortcut for replicaset. and here we can give
                                                     any name that is our choise ex., abcd-rs
                        spec:                    --> specification of replicaset
                          replicas: 3
                          selector:              --> this selector will select the group of pods by label
                            matchLabels:
                              app: swiggy-rs
                        template:
                          containers:
                            - name: cont1
                              image: nginx
perfect indentain is,
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  labels:
    app: swiggy
  name: swiggy-rs
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
        - name: cont1
          image: nginx
--> kubectl create -f abcd.yml --> creating resource file from file abcd.yml( creating pod from resource file abcd.yml)
--> kubectl get pods           --> here we seen the three riplicas and in running state 
--> kubectl delete pod podname --> to delete one pod from replica set and at the deleting pod immediatly another pod will be created bcs here 
                                    we creating pod as replicaset method. and we are having swiggy as a label for these 3 pods.
--> kubectl run zomato1 --image=nginx --> crating pod with other label by imperative method
--> kubectl run zomato2 --image=nginx
--> kubectl run zomato3 --image=nginx
now to see the pods with labels by 
--> kubectl get pods --show-labels --> here we can see the 3 pods with swiggy label and 3 pods with zomato label
                                       so by this example we can understand what exactly happen to how to use label while pod creation.
--> kubectl get replicaset --> it will show the how many replicas we have and with replicaset name as well.
                              {if we create pod as normal it doesnt give replicas of pod but when when use rs method than we get replicas}
--> kubectl api-resources --> is to describe full info kubernatis                               
--> kubectl describe rs swiggy-rs --> it will give complete info swiggy rs replica set
EVENTS: actions having in kubernatis cluster
--> kubectl scale rs swiggy-rs --replicas=10  --> it scale the swiggy-rs label pods
                                       ( and here only the swiggy labeled pods will be scalled but not the zomato pods bcz we have applied 
                                         scale for only replica sets but not for normal pods)
--> kubectl scale rs swiggy-rs --replicas=5  --> it scale down the replicasets 
--> kubectl delete rs swiggy-rs       --> it will delete the replicaset of swiggy labled pods, but here the containers not going to be 
                                                recreated after immediate delition like docker swarm or replicaset bcz here we are delting the 
                                                entire replicaset but not only the pod. 
--> kubectl get pods  --> so now it will give now only the zomoto pods only bcz the reason is explained in above statement.


LIMITATIONS OF REPLICA SET:
    replica set will creates the copys of pods only.
    replica sets will not work for rolling updates and rollbacks which means when we try to update replicaset version it not going to be work.
    for this purpose we need to use DEPLOYMENT in kubernetis.
    ( for example we have 3 pods and the version of that three pods will be same for all ex., v1, bcz they are the copys of pods only, and 
      if we want to update the one pod version from v1 to v2 than that replicaset not going to work so this can be achieved by deployment.
DEPLOYMENT:    
       the DEPLOYMETN is an other function of kubernatis which will do whatever the replicaset is do and it can alos do whatever replicaset 
       will not do and such are rollbacks and rolling updates etc.,
       with deploymet we can achieve zero downtime 
       with deployment we can update container image and configuration
       in deployment we can update the version of application and we can track history of changes of application.
       
  normal pod will creates ----> pods only
  replicaset will creates ---> pods  ( the replicaset will creates only the replicas only)  
  deployment will creates ----> replicaset ----> pods ( the eployment will creates rs and it is able to update the apllication as well)
  
  creating deployment object:  just remove replicaset from rs manifest file and replace that with deployment.
    --> vim abcd.yml
                    
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: swiggy
  name: swiggy-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
        - name: cont1
          image: nginx
--> kubectl create -f abcd.yml  --> creating object from manifestfile
--> kubctl get deployment ---> it can show the creted deployment
--> kubectl get rs --> now we can see the replicaset created by deployment object method 
--> kubectl get pods --> we can see the pods which are created by deployment object
               so by above process we can say that the deployment will create rs and pods 
--> kubectl delete pods swiggy-deploy-64cd94d7f4-bnm52  --> first the mentioned pod will get deleted and immideatly the pod will be recreated
                                                             this is called as zero downtime.
 the main purpose of deployment is update the application, this means to change or update the papplication we need to change the image so, 
 in abcd.yml manifest file change the image name as nginx to nginx:1.14(for example)
 i.e,
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: swiggy
  name: swiggy-deploy               --> deploy is the shortcut for deployment.
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
        - name: cont1
          image: nginx:1.14
--> kubectl apply -f abcd.yml
 
 kubectl create vs kubectl apply:
            --> kubectl crete is to create the object for the first time, kubectl apply means it apply the changes for alredy existing objects.
                if use kubectl create after changing the image version than the existing version of pod will deleted first and a new version 
                pod will created again.
--> kubectl describe deploy --> now it gives update version of image of replicaset as nginx:1.14
--> kubectl rollout status deployment/swiggy-deploy ---> its rollout the previous 
                                                     actually the rollback to the previous version of deployment cant be done by two ways 
                                                     1. go the manifest file and change to the previous version 
                                                     2. --> kubectl edit deploy swiggy-deploy
                                                             now in the opened file change the version than again run this file.
  
         
 HISTORY:
 
 
   1  mkdir abcd
    2  cd abcd/
    3  vim minikube.sh
    4  sh minikube.sh
    5  rm -rf *
    6  vim abc.yml
    7  kubectl create -f abc.yml
    8  kubectl get po
    9  kubectl delete po swiggy-rs-zqgqf
   10  kubectl get po
   11  kubectl delete pod swiggy-rs-z7667
   12  kubectl get po
   13  kubectl run zomato --image=nginx
   14  kubectl run zomato1 --image=nginx
   15  kubectl run zomato2 --image=nginx
   16  kubectl get po
   17  kubectl get po --show-labels
   18  kubectl get replicaset
   19  kubectl get rs
   20  kubectl api-resources
   21  kubectl get rs
   22  kubectl desribe rs swiggy-rs
   23  kubectl describe rs swiggy-rs
   24  kubectl get rs
   25  kubectl scale rs swiggy-rs --replicas=10
   26  kubectl get rs
   27  kubectl get po
   28  kubectl scale rs swiggy-rs --replicas=5
   29  kubectl get po
   30  kubectl delete rs swiggy-rs
   31  kubectl get po
   32  kubectl delete pods -n default
   33  kubectl delete all -n default
   34  kubectl delete all -n=default
   35  kubectl get po
   36  kubectl delete pod zomato zomato1 zomato2
   37  kubectl get po
   38  vim abc.yml
   39  kubectl create -f abc.yml
   40  kubectl get deployment
   41  kubectl get rs
   42  kubectl get po
   43  kubectl delete pod swiggy-deploy-64cd94d7f4-p9ztf
   44  kubectl get po
   45  kubectl describe deploy
   46  vim abc.yml
   47  kubectl create -f abc.yml
   48  kubectl apply -f abc.yml
   49  kubectl describe deploy
   50  vim abc.yml
   51  kubectl apply -f abc.yml
   52  kubectl describe deploy
   53  kubectl get po
   54  kubectl rollout status deployment/swiggy-deploy
   55  kubectl describe deploy
   56  kubectl get deploy
   57  kubectl get po
   58  kubectl edit deploy swiggy-deploy
   59  kubectl get deploy
   60  kubectl get po
   61  kubectl describe deploy
   62  kubectl edit deploy swiggy-deploy
   63  kubectl get po
   64  kubectl edit deploy swiggy-deploy
   65  kubectl get po
   66  kubectl edit deploy swiggy-deploy
   67  cat abc.yml
   68  history
*********************************************************************************************************************************************
12-06-23,day04.
KOPS(KUBERNATES OPERATIONS): it is a application which automates everything

kOps, also known as Kubernetes operations, is an open-source tool that helps you create, destroy, upgrade, 
and maintain a highly available, production-grade Kubernetes cluster.
Depending on the requirement, kOps can also provision cloud infrastructure.
kOps is mostly used in deploying AWS and GCE Kubernetes clusters. But officially, the tool only supports AWS.
Support for other cloud providers (such as DigitalOcean, GCP, and OpenStack) are in the beta stage.


ADVANTAGES:
•	Automates the provisioning of AWS and GCE Kubernetes clusters
•	Deploys highly available Kubernetes masters
•	Supports rolling cluster updates
•	Autocompletion of commands in the command line
•	Generates Terraform and CloudFormation configurations
•	Manages cluster add-ons.
•	Supports state-sync model for dry-runs and automatic idempotency
•	Creates instance groups to support heterogeneous clusters 
               
ALTERNATIVES:
Amazon EKS , MINIKUBE, KUBEADM, RANCHER, TERRAFORM, HELM.

** the Kops is an third party application which is used to automate the entire infrastructure. and inorder use this to automate cloud
   infrastructure we need to create user and generate some keys for this user and have to assign these keys to aws cloud than only the aws will
   work work with this third party application.
   
CREATING USER AND GENERATING KEYS:
lets search as user in aws search bar and than,                             (the IAM key is used to create ifra in aws cloud)

iam--> user--> add users--> username(anything) --> next--> attach plicies directly--> 
in permission policies
administrationAccess--> next--> creater user
in users click on user(which we have created user)--> security credentials--> create access key--> cli--> create access key
now we have access key and secrete access key save these or download them as csv file at anywhere.


STEP1:
     to work with EC2 by using KOPS we need to provide the kops keys(permissions) which we have generated are to assign to ec2 instance.
    --> aws configure                                                         --> configuring ec2 with created user(kops) accesskey.
        AWS Access Key ID [None]: AKIA2NTY5YYPCLXAGLZD                         --> giving aws key
        AWS Secret Access Key [None]: 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 --> giving secret key
        Default region name [None]: ap-south-1                                 --> giving region name 
        default output format: table                                           --> gibin default output format as table.
    
    if we mistake giving the keys information above is wrong than we can edit them to correct by below process
    --> cd .aws
    --> ll --> config, credentials
    --> vim config ---> give the correct configureations
    --> vim credentials --> give correct credentials

STEP2: DOWNLOADING KOPS AND KUBECTL
    --> curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
                                                        above link is for downloading kubectl commandline tool
    --> wget https://github.com/kubernetes/kops/releases/download/v1.24.1/kops-linux-amd64
                                                         this link for downloading kops application
    --> ll --> will give the above two download file but we need to do some exicutable operations by using above file so we need 
                give the exicutable permission for above two files so,
    --> chmod +x kops-linux-amd64 kubectl     ---> giving exicutable permissions two kop and kubctl
    
    in linux all exicuitable files should be in bin directory only than only they are able to exicuitable so we need to move the above exicutable
    files in to bin directory so,
    
    --> mv kubectl /usr/local/bin/kubectl  --> moving kubectl into bin
    --> mv kops-linux-amd64 /usr/local/bin/kops  --> moving kops into the bin directory
    
     we have downloaded the third partly application files so we need to give the path from where these files need to exicute i.e, bin,
    --> vim .bashrc 
              export PATH=$PATH:/usr/local/bin
    --> source .bashrc   ---> to update this path changes in .bashrc          
    
    now we can exicute the commands from kubectl and kops to check this we can check the versions i.e,
    --> kops version
    --> kubectl version

STEP3: CREATING BUCKETS
      all the clustor information is stored in buckets so we need to create the buckets
    --> aws s3api create-bucket --bucket sairamana.k8s.local --region us-east-1   --> its creates bucket and sometimes it could not create bcz of
                                                                                    unavailably of region so at that time we simply change the 
                                                                                    region and create again than it will work.
     --------------------------------------
     |            CreateBucket            |
        ----------+------------------------+
      |  Location |  /sairamana.k8s.local  |
      +-----------+------------------------+
      
   sometimes we accidentally able to delete the pods than our application wont be work so to overcome this we need to give the version to 
   the buckets as below command than we can retreive the deleted pods or information in bucket
                                       or
   in a container if we deleted one object so if we want retrieve that deleted object we need enable the version configureatin                   
                                  
   --> aws s3api put-bucket-versioning --bucket sairamana.k8s.local --region us-east-1 --versioning-configuration Status=Enabled
      note: if we change the region while creating bucket than we need to change the region alos in aws config i.e, 
      ............................
      --> vim .aws/config
                region = us-east-1
      ............................
   now whatever the information avaiblein kops cluster is needs to export into the bucket so,
   -->  export KOPS_STATE_STORE=s3://sairamana.k8s.local
                   this means all the objects we created by kops such as cont,replicasets, pods .etc., are exportng into the bucket.
                   
STEP4: CREATING CLUSTER BY KOPS:
  --> kops create cluster --name sairamana.k8s.local --zones us-east-1a --master-size t2.medium --node-size t2.micro
  ..........
  --> kops get cluster --> gives the clusters
  --> kops edit cluster sairamana.k8s.local --> to edit cluster information
  --> kops edit ig --name=saiamana.k8s.local master-us-east-1a  --> to edit the master information
                                         here ig --> instance group
  --> kops edit ig --name=sairamana.k8s.local nodes-us-east-1a --> to edit the nodes information
  --> kops update cluster --name sairamana.k8s.local --yes --admin  --> wait 10 min than cluster will get updated with changes we made 
                                                                        and we get multiple errors while updating but its doesnt effect.
  --> kops validate cluster ---> we can see what happening while updating cluster
  
  WHILE UPDATING CLUSTER AT LAST WE WILL GET AS YOUR CLUSTER IS READY 
  
  
  
  
  
  
                                       


  
                   
                   
   
    
   
      
                                                                           
                                                                                    

           
              
               
    

    
    

     



                                    
                                    

                        
                            
                        



        
              
              

